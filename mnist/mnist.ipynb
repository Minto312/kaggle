{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf \n",
    "\n",
    "train_data = pd.read_csv('/code/mnist/train.csv')\n",
    "test_data = pd.read_csv('/code/mnist/test.csv')\n",
    "\n",
    "X = train_data.drop('label', axis=1)\n",
    "Y = train_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.astype('float32') / 255\n",
    "test_data = test_data.astype('float32') / 255\n",
    "\n",
    "Y = tf.keras.utils.to_categorical(Y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = X[:round(X.shape[0] * 0.8)]\n",
    "check_x = X[round(X.shape[0] * 0.8):]\n",
    "\n",
    "train_y = Y[:round(Y.shape[0] * 0.8)]\n",
    "check_y = Y[round(Y.shape[0] * 0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# inputs = tf.keras.Input(shape=(784,))\n",
    "# x_1 = Dense(256, activation='relu')(inputs)\n",
    "# x_2 = Dropout(0.2)(x_1)\n",
    "# outputs = Dense(10, activation='softmax')(x_2)\n",
    "\n",
    "# model = tf.keras.Model(inputs=inputs, outputs=outputs, name='mnist_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.values.reshape(-1, 28, 28, 1)\n",
    "check_x = check_x.values.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33600, 28, 28, 1)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
    "\n",
    "\n",
    "inputs = tf.keras.Input(shape=(28, 28, 1))\n",
    "x_1 = Conv2D(32, kernel_size=(5, 5), strides=1, activation='relu', padding='same')(inputs)\n",
    "x_2 = MaxPooling2D(pool_size=(2, 2), strides=2, padding='same')(x_1)\n",
    "x_3 = Flatten()(x_2)\n",
    "x_4 = Dropout(0.4)(x_3)\n",
    "outputs = Dense(10, activation='softmax')(x_4)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs, name='mnist_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.categorical_crossentropy,\n",
    "    metrics=[tf.keras.metrics.categorical_accuracy],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33600, 10)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210/210 [==============================] - 4s 19ms/step - loss: 0.5055 - categorical_accuracy: 0.8576 - val_loss: 0.2405 - val_categorical_accuracy: 0.9305\n",
      "Epoch 2/20\n",
      "  7/210 [>.............................] - ETA: 3s - loss: 0.2437 - categorical_accuracy: 0.9330"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210/210 [==============================] - 4s 17ms/step - loss: 0.1986 - categorical_accuracy: 0.9432 - val_loss: 0.1481 - val_categorical_accuracy: 0.9571\n",
      "Epoch 3/20\n",
      "210/210 [==============================] - 3s 16ms/step - loss: 0.1361 - categorical_accuracy: 0.9606 - val_loss: 0.1144 - val_categorical_accuracy: 0.9668\n",
      "Epoch 4/20\n",
      "210/210 [==============================] - 3s 16ms/step - loss: 0.1104 - categorical_accuracy: 0.9678 - val_loss: 0.0962 - val_categorical_accuracy: 0.9734\n",
      "Epoch 5/20\n",
      "210/210 [==============================] - 4s 17ms/step - loss: 0.0933 - categorical_accuracy: 0.9722 - val_loss: 0.0900 - val_categorical_accuracy: 0.9759\n",
      "Epoch 6/20\n",
      "210/210 [==============================] - 3s 17ms/step - loss: 0.0814 - categorical_accuracy: 0.9750 - val_loss: 0.0801 - val_categorical_accuracy: 0.9783\n",
      "Epoch 7/20\n",
      "210/210 [==============================] - 4s 17ms/step - loss: 0.0744 - categorical_accuracy: 0.9780 - val_loss: 0.0787 - val_categorical_accuracy: 0.9775\n",
      "Epoch 8/20\n",
      "210/210 [==============================] - 4s 17ms/step - loss: 0.0679 - categorical_accuracy: 0.9799 - val_loss: 0.0776 - val_categorical_accuracy: 0.9759\n",
      "Epoch 9/20\n",
      "210/210 [==============================] - 3s 17ms/step - loss: 0.0613 - categorical_accuracy: 0.9809 - val_loss: 0.0694 - val_categorical_accuracy: 0.9807\n",
      "Epoch 10/20\n",
      "210/210 [==============================] - 3s 16ms/step - loss: 0.0561 - categorical_accuracy: 0.9820 - val_loss: 0.0679 - val_categorical_accuracy: 0.9807\n",
      "Epoch 11/20\n",
      "210/210 [==============================] - 4s 17ms/step - loss: 0.0527 - categorical_accuracy: 0.9836 - val_loss: 0.0659 - val_categorical_accuracy: 0.9826\n",
      "Epoch 12/20\n",
      "210/210 [==============================] - 4s 17ms/step - loss: 0.0477 - categorical_accuracy: 0.9849 - val_loss: 0.0651 - val_categorical_accuracy: 0.9804\n",
      "Epoch 13/20\n",
      "210/210 [==============================] - 3s 17ms/step - loss: 0.0450 - categorical_accuracy: 0.9855 - val_loss: 0.0644 - val_categorical_accuracy: 0.9817\n",
      "Epoch 14/20\n",
      "210/210 [==============================] - 3s 17ms/step - loss: 0.0426 - categorical_accuracy: 0.9871 - val_loss: 0.0630 - val_categorical_accuracy: 0.9817\n",
      "Epoch 15/20\n",
      "210/210 [==============================] - 3s 17ms/step - loss: 0.0400 - categorical_accuracy: 0.9877 - val_loss: 0.0611 - val_categorical_accuracy: 0.9824\n",
      "Epoch 16/20\n",
      "210/210 [==============================] - 4s 17ms/step - loss: 0.0389 - categorical_accuracy: 0.9880 - val_loss: 0.0609 - val_categorical_accuracy: 0.9829\n",
      "Epoch 17/20\n",
      "210/210 [==============================] - 4s 17ms/step - loss: 0.0364 - categorical_accuracy: 0.9885 - val_loss: 0.0596 - val_categorical_accuracy: 0.9838\n",
      "Epoch 18/20\n",
      "210/210 [==============================] - 3s 17ms/step - loss: 0.0360 - categorical_accuracy: 0.9887 - val_loss: 0.0582 - val_categorical_accuracy: 0.9835\n",
      "Epoch 19/20\n",
      "210/210 [==============================] - 3s 16ms/step - loss: 0.0342 - categorical_accuracy: 0.9892 - val_loss: 0.0617 - val_categorical_accuracy: 0.9820\n",
      "Epoch 20/20\n",
      "210/210 [==============================] - 3s 16ms/step - loss: 0.0328 - categorical_accuracy: 0.9891 - val_loss: 0.0587 - val_categorical_accuracy: 0.9835\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        patience=2, \n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        '/code/mnist/data/temp/mnist_sequential_{epoch:03d}_{val_loss:.4f}.h5',\n",
    "        save_best_only=True\n",
    "    ),\n",
    "    tf.keras.callbacks.TensorBoard(\n",
    "        log_dir='/code/mnist/logs',\n",
    "        histogram_freq=1\n",
    "    ),\n",
    "]\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 20\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "history = model.fit(train_x, train_y, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_split=VALIDATION_SPLIT, callbacks=callbacks)\n",
    "model.save('/code/mnist/mnist_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mnist_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 28, 28, 32)        832       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 14, 14, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 6272)              0         \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 10)                62730     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 63562 (248.29 KB)\n",
      "Trainable params: 63562 (248.29 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 0s 1ms/step - loss: 0.0513 - categorical_accuracy: 0.9840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05126721039414406, 0.9840475916862488]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(check_x, check_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 0.9811905026435852\n",
    "- 0.98416668176651 maxpooling\n",
    "- 0.9783333539962769 karnel(5,5) => (3,3) & padding 'same'\n",
    "- 0.9825000166893005 karnel => (3,3)\n",
    "- 0.9840475916862488 drop 0.2 => 0.4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
